version: '3.7'

services:

  elasticsearch:
    # image: docker.elastic.co/elasticsearch/elasticsearch:${TAGELK}
    image: elasticsearch:${TAGELK}
    container_name: elasticsearch
    environment:
      - node.name=elasticsearch
      - discovery.seed_hosts=elasticsearch
      - cluster.initial_master_nodes=elasticsearch
      - cluster.name=docker-cluster
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - esdata:/usr/share/elasticsearch/data
    ports:
      - 9200:9200

  kibana:
    image: docker.elastic.co/kibana/kibana:${TAGELK}
    container_name: kibana
    environment:
      ELASTICSEARCH_URL: "http://elasticsearch:9200"
    ports:
      - 5601:5601
    depends_on:
      - elasticsearch

  # logstash:
  #   image: docker.elastic.co/logstash/logstash:${TAGELK}
  #   container_name: logstash
  #   depends_on: elasticsearch

  apmserver:
    image: docker.elastic.co/apm/apm-server:${TAGELK}
    container_name: apm_server
    command: --strict.perms=false # -e flag to log to stderr and disable syslog/file output
    ports:
      - 8200:8200
    environment:
      - apm-server.host=app:8000
      - setup.kibana.host=kibana:5601
      - output.elasticsearch.hosts=["elasticsearch:9200"]
      - apm-server.rum.enabled=true
      - apm-server.rum.event_rate.limit=300
      - apm-server.rum.event_rate.lru_size=1000
      - apm-server.rum.allow_origins=['*']
      - apm-server.rum.library_pattern="node_modules|bower_components|~"
      - apm-server.rum.exclude_from_grouping="^/webpack"
      - apm-server.rum.source_mapping.cache.expiration=5m
      - apm-server.rum.source_mapping.index_pattern="apm-*-sourcemap*"
    # volumes:
      # - ./.apm-server.yml:/usr/share/apm-server/apm-server.yml
      # - './elk/apm-server/scripts/apm-server.docker.yml:/usr/share/apm-server/apm-server.yml:ro'
      # - './elk/apm-server/scripts/setup-beat.sh:/usr/local/bin/setup-beat.sh:ro'
    depends_on:
      - elasticsearch
      - kibana

  filebeat:
    image: docker.elastic.co/beats/filebeat:${TAGELK}
    container_name: filebeat
    command: --strict.perms=false -e  # -e flag to log to stderr and disable syslog/file output
    # If the host system has logs at "/var/log", mount them at "/mnt/log"
    # inside the container, where Filebeat can find them.
    # volumes: ['/var/log:/mnt/log:ro']
    volumes:
      - './elk/filebeat/setup-beat.sh:/usr/local/bin/setup-beat.sh:ro'
    depends_on: ['elasticsearch', 'kibana']

  metricbeat:
    image: docker.elastic.co/beats/metricbeat:${TAGELK}
    container_name: metricbeat
    # The commented sections below enable Metricbeat to monitor the Docker host,
    # rather than the Metricbeat container. It's problematic with Docker for
    # Windows, however, since "/proc", "/sys" etc. don't exist on Windows.
    # The same likely applies to OSX (needs testing).
    # volumes:
    #   - /proc:/hostfs/proc:ro
    #   - /sys/fs/cgroup:/hostfs/sys/fs/cgroup:ro
    #   - /:/hostfs:ro
    command: --strict.perms=false -e  # -e flag to log to stderr and disable syslog/file output
    volumes:
      - './elk/metricbeat/setup-beat.sh:/usr/local/bin/setup-beat.sh:ro'
    depends_on: ['elasticsearch', 'kibana']



  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./prometheus/:/etc/prometheus/
      - prometheusdata:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention=200h'
      - '--web.enable-lifecycle'
    ports:
      - 9090:9090

  prometheus-mssql-exporter:
    image: awaragi/prometheus-mssql-exporter
    container_name: prometheus-mssql-exporter
    environment:
        SERVER: "10.35.1.60"
        USERNAME: "usr_prometheus_export"
        PASSWORD: "d@123456"
        DEBUG: "app"
    depends_on:
      - prometheus
    ports:
      - 4000:4000
    volumes:
      - ./prometheus/exporter/mssql/:/etc/prometheus/exporter/mssql/

  prometheus-snmp-exporter:
    image: prom/snmp-exporter #quay.io/prometheus/snmp-exporter
    container_name: prometheus-snmp-exporter
    volumes:
      - ./prometheus/exporter/snmp/:/etc/prometheus/exporter/snmp/
    ports:
      - 9116:9116
      - 116:116/udp
    restart: always
    command: --config.file=/etc/snmp_exporter/snmp.yml

  cadvisor:
    image: google/cadvisor:latest
    container_name: container_advisor
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:rw
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    ports:
      - 8084:8080


  grafana:
    image: grafana/grafana:${TAGGRAF}
    container_name: grafana
    #user: "104"
    depends_on:
      - prometheus
    ports:
      - 3000:3000
    volumes:
      - grafanadata:/var/lib/grafana
      - ./grafana/provisioning/:/etc/grafana/provisioning/


  sql:
      image: "mcr.microsoft.com/mssql/server:latest"
      container_name: sql
      environment:
        SA_PASSWORD: "Senh@123"
        ACCEPT_EULA: "Y"
      volumes:
        - sqldata:/var/opt/mssql
      ports:
        - 1433:1433


  app:
    container_name: app
    build: ./aspnetapp/aspnetapp
    ports:
      - 8000:80
    depends_on:
      - sql

volumes:
  esdata:
    driver: local
  sqldata:
    driver: local
  prometheusdata:
    driver: local
  grafanadata:
    driver: local


# logstash:
#     image: docker.elastic.co/logstash/logstash:${TAG}
#     container_name: logstash
#     secrets:
#       - source: logstash.conf
#         target: /usr/share/logstash/pipeline/logstash.conf
#       - source: logstash.yml
#         target: /usr/share/logstash/config/logstash.yml
#       - source: logstash.keystore
#         target: /usr/share/logstash/config/logstash.keystore
#       - source: ca.crt
#         target: /usr/share/logstash/config/certs/ca/ca.crt
#     networks: ['stack']
#     depends_on: ['elasticsearch']
#     healthcheck:
#       test: bin/logstash -t
#       interval: 60s
#       timeout: 50s
#       retries: 5

#   auditbeat:
#     image: docker.elastic.co/beats/auditbeat:${TAG}
#     container_name: auditbeat
#     command: -e --strict.perms=false # -e flag to log to stderr and disable syslog/file output
#     cap_add: ['AUDIT_CONTROL', 'AUDIT_READ']
#     secrets:
#       - source: auditbeat.yml
#         target: /usr/share/auditbeat/auditbeat.yml
#       - source: auditbeat.keystore
#         target: /usr/share/auditbeat/auditbeat.keystore
#       - source: ca.crt
#         target: /usr/share/auditbeat/certs/ca/ca.crt
#     # Auditbeat must run in the main process namespace.
#     pid: host
#     volumes:
#       - './scripts/setup-beat.sh:/usr/local/bin/setup-beat.sh:ro'
#     networks: ['stack']
#     depends_on: ['elasticsearch', 'kibana']
#     healthcheck:
#       test: auditbeat --strict.perms=false test config
#       interval: 30s
#       timeout: 15s
#       retries: 5

#   filebeat:
#     image: docker.elastic.co/beats/filebeat:${TAG}
#     container_name: filebeat
#     command: --strict.perms=false -e  # -e flag to log to stderr and disable syslog/file output
#     # If the host system has logs at "/var/log", mount them at "/mnt/log"
#     # inside the container, where Filebeat can find them.
#     # volumes: ['/var/log:/mnt/log:ro']
#     secrets:
#       - source: filebeat.yml
#         target: /usr/share/filebeat/filebeat.yml
#       - source: filebeat.keystore
#         target: /usr/share/filebeat/filebeat.keystore
#       - source: ca.crt
#         target: /usr/share/filebeat/certs/ca/ca.crt
#     volumes:
#       - './scripts/setup-beat.sh:/usr/local/bin/setup-beat.sh:ro'
#     networks: ['stack']
#     depends_on: ['elasticsearch', 'kibana']
#     healthcheck:
#       test: filebeat test config
#       interval: 30s
#       timeout: 15s
#       retries: 5

#   heartbeat:
#     image: docker.elastic.co/beats/heartbeat:${TAG}
#     container_name: heartbeat
#     command: --strict.perms=false -e  # -e flag to log to stderr and disable syslog/file output
#     secrets:
#       - source: heartbeat.yml
#         target: /usr/share/heartbeat/heartbeat.yml
#       - source: heartbeat.keystore
#         target: /usr/share/heartbeat/heartbeat.keystore
#       - source: ca.crt
#         target: /usr/share/heartbeat/certs/ca/ca.crt
#     volumes:
#       - './scripts/setup-beat.sh:/usr/local/bin/setup-beat.sh:ro'
#     networks: ['stack']
#     depends_on: ['elasticsearch', 'kibana']
#     healthcheck:
#       test: heartbeat test config
#       interval: 30s
#       timeout: 15s
#       retries: 5

#   metricbeat:
#     image: docker.elastic.co/beats/metricbeat:${TAG}
#     container_name: metricbeat
#     # The commented sections below enable Metricbeat to monitor the Docker host,
#     # rather than the Metricbeat container. It's problematic with Docker for
#     # Windows, however, since "/proc", "/sys" etc. don't exist on Windows.
#     # The same likely applies to OSX (needs testing).
#     # volumes:
#     #   - /proc:/hostfs/proc:ro
#     #   - /sys/fs/cgroup:/hostfs/sys/fs/cgroup:ro
#     #   - /:/hostfs:ro
#     command: --strict.perms=false -e  # -e flag to log to stderr and disable syslog/file output
#     secrets:
#       - source: metricbeat.yml
#         target: /usr/share/metricbeat/metricbeat.yml
#       - source: metricbeat.keystore
#         target: /usr/share/metricbeat/metricbeat.keystore
#       - source: ca.crt
#         target: /usr/share/metricbeat/certs/ca/ca.crt
#     volumes:
#       - './scripts/setup-beat.sh:/usr/local/bin/setup-beat.sh:ro'
#     networks: ['stack']
#     depends_on: ['elasticsearch', 'kibana']
#     healthcheck:
#       test: metricbeat test config
#       interval: 30s
#       timeout: 15s
#       retries: 5

#   packetbeat:
#     image: docker.elastic.co/beats/packetbeat:${TAG}
#     container_name: packetbeat
#     # Packetbeat needs some elevated privileges to capture network traffic.
#     # We'll grant them with POSIX capabilities.
#     cap_add: ['NET_RAW', 'NET_ADMIN']
#     # Use "host mode" networking to allow Packetbeat to capture traffic from
#     # the real network interface on the host, rather than being isolated to the
#     # container's virtual interface.
#     network_mode: host
#     # Since we did that, Packetbeat is not part of the "stack" Docker network
#     # that the other containers are connected to, and thus can't resolve the
#     # hostname "elasticsearch". Instead, we'll tell it to find Elasticsearch
#     # on "localhost", which is the Docker host machine in this context.
#     command: -e -E 'output.elasticsearch.hosts=["localhost:9200"]'
#     depends_on: ['elasticsearch']
#     command: --strict.perms=false -e -E output.elasticsearch.hosts="https://localhost:9200" # -e flag to log to stderr and disable syslog/file output
#     secrets:
#       - source: packetbeat.yml
#         target: /usr/share/packetbeat/packetbeat.yml
#       - source: packetbeat.keystore
#         target: /usr/share/packetbeat/packetbeat.keystore
#       - source: ca.crt
#         target: /usr/share/packetbeat/certs/ca/ca.crt
#     volumes:
#       - './scripts/setup-beat.sh:/usr/local/bin/setup-beat.sh:ro'
#     depends_on: ['elasticsearch', 'kibana']
#     healthcheck:
#       test: packetbeat test config
#       interval: 30s
#       timeout: 15s
#       retries: 5
